/*
* Copyright 2019-2020 NVIDIA CORPORATION.
*
* Licensed under the Apache License, Version 2.0 (the "License");
* you may not use this file except in compliance with the License.
* You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*/

#pragma once

#include <exception>
#include <memory>
#include <string>
#include <unordered_map>

#include <claraparabricks/genomeworks/cudamapper/types.hpp>
#include <claraparabricks/genomeworks/utils/allocator.hpp>
#include <claraparabricks/genomeworks/cudamapper/index.hpp>

namespace claraparabricks
{

namespace genomeworks
{

namespace io
{
class FastaParser;
} // namespace io

namespace cudamapper
{

class IndexHostCopyBase;

/// IndexCache - Creates indices, stores them in host memory and on demands moves them to device memory
///
/// Class contains separate caches for query and target. In this example query cache is going to be used, target cache is equivalent.
/// The user generates indices and stores them in host memory using generate_content_query_host(). The user then copies some of those indices
/// to device memory using start_generating_content_query_device() and finish_generating_content_query_device(). It is user's responsibility
/// to make sure that indices requested by start_generating_content_query_device() were generated by generate_content_query_host().
/// Memory copy to device is done asynchronously, the user should make sure that every call to start_generating_content_query_device() is
/// followed by a call finish_generating_content_query_device().
/// The class tries to minimize the number of index creation and movemens, e.g. by reusing already existing indices, but not guarantees are given.
class IndexCache
{
public:
    /// \brief Constructor only initializes cache, no index is generated at this point
    ///
    /// \param same_query_and_target true means that both query and target files are the same, meaning that if some index exists in query cache it can also be used by target cache directly
    /// \param allocator allocator to use for device arrays
    /// \param query_parser
    /// \param target_parser
    /// \param kmer_size see Index
    /// \param window_size see Index
    /// \param hash_representations see Index
    /// \param filtering_parameter see Index
    /// \param cuda_stream_generation index generation is done one this stream, device memory in resulting device copies of index will only we freed once all previously scheduled work on this stream has finished
    /// \param cuda_stream_copy D2H and H2D copies of indices will be done on this stream, device memory in resulting device copies of index will only we freed once all previously scheduled work on this stream has finished
    IndexCache(bool same_query_and_target,
               genomeworks::DefaultDeviceAllocator allocator,
               std::shared_ptr<genomeworks::io::FastaParser> query_parser,
               std::shared_ptr<genomeworks::io::FastaParser> target_parser,
               std::uint64_t kmer_size,
               std::uint64_t window_size,
               bool hash_representations           = true,
               double filtering_parameter          = 1.0,
               cudaStream_t cuda_stream_generation = 0,
               cudaStream_t cuda_stream_copy       = 0);

    /// \brief Generates indices on device and copies them to host memory
    ///
    /// If index already exists on host is may be reused.
    /// Indices from descriptors_of_indices_to_keep_on_device will be kept on device in addition to being to host. This is useful if the same indices
    /// are going to be requested by start_generating_content_query_device() immediately after this call.
    /// If skip_copy_to_host is ture indices are going to be kept on device and not copied to host. In that case descriptors_of_indices_to_cache must
    /// be equal to descriptors_of_indices_to_keep_on_device and there must be only one call to start_generating_content_query_device()
    ///
    /// \param descriptors_of_indices_to_cache
    /// \param descriptors_of_indices_to_keep_on_device
    /// \param skip_copy_to_host
    void generate_content_query_host(const std::vector<IndexDescriptor>& descriptors_of_indices_to_cache,
                                     const std::vector<IndexDescriptor>& descriptors_of_indices_to_keep_on_device = {},
                                     bool skip_copy_to_host                                                       = false);

    /// \brief Generates indices on device and copies them to host memory
    ///
    /// If index already exists it is not going to be regenerated.
    /// Indices from descriptors_of_indices_to_keep_on_device will be kept on device in addition to being to host. This is useful if the same indices
    /// are going to be requested by start_generating_content_target_device() immediately after this call.
    /// If skip_copy_to_host is ture indices are going to be kept on device and not copied to host. In that case descriptors_of_indices_to_cache must
    /// be equal to descriptors_of_indices_to_keep_on_device and there must be only one call to start_generating_content_target_device()
    ///
    /// \param descriptors_of_indices_to_cache
    /// \param descriptors_of_indices_to_keep_on_device
    /// \param skip_copy_to_host
    void generate_content_target_host(const std::vector<IndexDescriptor>& descriptors_of_indices_to_cache,
                                      const std::vector<IndexDescriptor>& descriptors_of_indices_to_keep_on_device = {},
                                      bool skip_copy_to_host                                                       = false);

    /// \brief Begins copying indices to device
    ///
    /// If index already exists on device it may be reused.
    /// This copy is done asynchronously, copy is finised by calling finish_generating_content_query_device().
    /// The user should make sure that every call to start_generating_content_query_device() is followed by a call to finish_generating_content_query_device()
    ///
    /// \param descriptors_of_indices_to_cache
    void start_generating_content_query_device(const std::vector<IndexDescriptor>& descriptors_of_indices_to_cache);

    /// \brief Waits for copy started in start_generating_content_query_device()
    ///
    /// The user should make sure that there was a call to start_generating_content_query_device() before this call
    void finish_generating_content_query_device();

    /// \brief Begins copying indices to device
    ///
    /// If index already exists on device it may be reused.
    /// This copy is done asynchronously, copy is finised by calling finish_generating_content_target_device().
    /// The user should make sure that every call to start_generating_content_target_device() is followed by a call to finish_generating_content_target_device()
    ///
    /// \param descriptors_of_indices_to_cache
    void start_generating_content_target_device(const std::vector<IndexDescriptor>& descriptors_of_indices_to_cache);

    /// \brief Waits for copy started in start_generating_content_target_device()
    ///
    /// The user should make sure that there was a call to start_generating_content_target_device() before this call
    void finish_generating_content_target_device();

    /// \brief Returns a pointer to requested index
    /// \return a pointer to requested index
    std::shared_ptr<const Index> get_index_from_query_cache(const IndexDescriptor& index_descriptor) const;

    /// \brief Returns a pointer to requested index
    /// \return a pointer to requested index
    std::shared_ptr<const Index> get_index_from_target_cache(const IndexDescriptor& index_descriptor) const;

private:
    using host_cache_t = std::unordered_map<IndexDescriptor,
                                            std::shared_ptr<const IndexHostCopyBase>,
                                            IndexDescriptorHash>;

    using device_cache_t = std::unordered_map<IndexDescriptor,
                                              std::shared_ptr<Index>,
                                              IndexDescriptorHash>;

    enum class CacheSelector
    {
        query_cache,
        target_cache
    };

    /// \brief Generates indices on device and copies them to host memory
    ///
    /// If index already exists on host is may be reused.
    /// Indices from descriptors_of_indices_to_keep_on_device will be kept on device in addition to being to host. This is useful if the same indices
    /// are going to be requested by start_generating_content_device() immediately after this call.
    /// If skip_copy_to_host is ture indices are going to be kept on device and not copied to host. In that case descriptors_of_indices_to_cache must
    /// be equal to descriptors_of_indices_to_keep_on_device and there must be only one call to start_generating_content_device()
    ///
    /// \param descriptors_of_indices_to_cache
    /// \param descriptors_of_indices_to_keep_on_device
    /// \param skip_copy_to_host
    /// \param which_cache
    void generate_content_host(const std::vector<IndexDescriptor>& descriptors_of_indices_to_cache,
                               const std::vector<IndexDescriptor>& descriptors_of_indices_to_keep_on_device,
                               bool skip_copy_to_host,
                               CacheSelector which_cache);

    /// \brief Begins copying indices to device
    ///
    /// If index already exists on device it may be reused.
    /// This copy is done asynchronously, copy is finised by calling finish_generating_content_device().
    /// The user should make sure that every call to start_generating_content_device() is followed by a call to finish_generating_content_device()
    ///
    /// \param descriptors_of_indices_to_cache
    /// \param which_cache
    void start_generating_content_device(const std::vector<IndexDescriptor>& descriptors_of_indices_to_cache,
                                         CacheSelector which_cache);

    /// \brief Waits for copy started in start_generating_content_device()
    ///
    /// The user should make sure that there was a call to start_generating_content_device() before this call
    /// \param which_cache
    void finish_generating_content_device(CacheSelector which_cache);

    /// \brief Returns a pointer to requested index
    /// \return a pointer to requested index
    std::shared_ptr<const Index> get_index_from_cache(const IndexDescriptor& index_descriptor,
                                                      CacheSelector which_cache) const;

    // Indices kept on host
    host_cache_t query_host_cache_;
    host_cache_t target_host_cache_;

    // Indices kept of device because of descriptors_of_indices_to_keep_on_device
    device_cache_t query_indices_kept_on_device_;
    device_cache_t target_indices_kept_on_device_;

    // Indices on device ready to be used
    device_cache_t query_device_cache_;
    device_cache_t target_device_cache_;

    // Indices currently being copied to device, they are going to replace the content of query_device_cache_
    // and target_device_cache_ after the next call to finish_generating_content_device(
    device_cache_t next_query_device_cache_;
    device_cache_t next_target_device_cache_;

    const bool same_query_and_target_;
    genomeworks::DefaultDeviceAllocator allocator_;
    std::shared_ptr<genomeworks::io::FastaParser> query_parser_;
    std::shared_ptr<genomeworks::io::FastaParser> target_parser_;
    const std::uint64_t kmer_size_;
    const std::uint64_t window_size_;
    const bool hash_representations_;
    const double filtering_parameter_;
    const cudaStream_t cuda_stream_generation_;
    const cudaStream_t cuda_stream_copy_;
};

/// IndexNotFoundException - Exception to be thrown if Index is reuqsted, but not found
class IndexNotFoundException : public std::exception
{
public:
    /// IndexType - Was the Index requested from host or device cache
    enum class IndexType
    {
        host_cache,
        device_cache
    };

    /// \brief constructor
    /// \param index_descriptor
    /// \param index_type was Index equested from host or device cache
    IndexNotFoundException(IndexDescriptor index_descriptor,
                           IndexType index_type);

    IndexNotFoundException(const IndexNotFoundException&) = default;
    IndexNotFoundException& operator=(const IndexNotFoundException&) = default;
    IndexNotFoundException(IndexNotFoundException&&)                 = default;
    IndexNotFoundException& operator=(IndexNotFoundException&&) = default;
    virtual ~IndexNotFoundException()                           = default;

    /// Returns the error message of the exception
    virtual const char* what() const noexcept;

private:
    const std::string error_message_;
};

} // namespace cudamapper

} // namespace genomeworks

} // namespace claraparabricks
